{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "# first, we need to import our essentia module.\n",
    "import essentia\n",
    "\n",
    "# as there are 2 operating modes in essentia which have the same algorithms,\n",
    "# these latter are dispatched into 2 submodules:\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "\n",
    "# # pylab contains the plot() function, as well as figure, etc... (same names as Matlab)\n",
    "# from pylab import plot, show, figure, imshow\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "# import machine learning packages\n",
    "import theano\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import dill\n",
    "\n",
    "import pydot as pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"jake_data/train_all.pkl\")\n",
    "test = pd.read_pickle(\"jake_data/test_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out some data to make it better distributed\n",
    "# train = train[0:21600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataframe\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n",
      "48600\n",
      "5400\n",
      "24300\n"
     ]
    }
   ],
   "source": [
    "spectType = \"melbands_log_file\"\n",
    "\n",
    "num_channels = 1\n",
    "\n",
    "num_columns = 9999999999\n",
    "for i in train[spectType]:\n",
    "    if (len(i[0]) < num_columns):\n",
    "        num_columns = len(i[0])\n",
    "\n",
    "num_rows = len(train[spectType][0])\n",
    "\n",
    "# need to figure out solution for different audio lenghts, jagged arrays?\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "X_test = np.zeros(shape=(len(test),1,num_rows,num_columns))\n",
    "c = 0\n",
    "for i in test[spectType]:\n",
    "    l = i.shape[1]\n",
    "    b = int(math.floor((l-num_columns)/2))\n",
    "    tp = i[0:num_rows,b:(b + num_columns)]\n",
    "    X_test[c,0,:,:] = tp\n",
    "    c = c + 1\n",
    "    \n",
    "X_train = np.zeros(shape=(len(train),1,num_rows,num_columns))\n",
    "c = 0\n",
    "for i in train[spectType]:\n",
    "    l = i.shape[1]\n",
    "    b = int(math.floor((l-num_columns)/2))\n",
    "    tp = i[0:num_rows,b:(b + num_columns)]\n",
    "    X_train[c,0,:,:] = tp\n",
    "    c = c + 1\n",
    "\n",
    "Y_train = np.zeros(shape=(len(train),2)) \n",
    "\n",
    "c = 0\n",
    "b = 0\n",
    "s = 0\n",
    "for i in train[\"output\"]:\n",
    "    if (i == \"bonafide\"):\n",
    "        b = b + 1\n",
    "        Y_train[c,:] = [np.float64(0.0),np.float64(1.0)]\n",
    "    else:\n",
    "        s = s + 1\n",
    "        Y_train[c,:] = [np.float64(1.0),np.float64(0.0)]\n",
    "    c = c + 1\n",
    "print(b)\n",
    "print(s)\n",
    "\n",
    "Y_test = np.zeros(shape=(len(test),2)) \n",
    "\n",
    "c = 0\n",
    "b = 0\n",
    "s = 0\n",
    "for i in test[\"output\"]:\n",
    "    if (i == \"bonafide\"):\n",
    "        b = b + 1\n",
    "        Y_test[c,:] = [np.float64(0.0),np.float64(1.0)]\n",
    "    else:\n",
    "        s = s + 1\n",
    "        Y_test[c,:] = [np.float64(1.0),np.float64(0.0)]\n",
    "    c = c + 1\n",
    "       \n",
    "print(b)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], num_channels, num_rows, num_columns)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_channels, num_rows, num_columns)\n",
    "\n",
    "num_labels = Y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(num_channels,num_rows,num_columns),data_format='channels_first'))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ELU(alpha=1.0)) \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ELU(alpha=1.0)) \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ELU(alpha=1.0)) \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 38, 123)       320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 36, 121)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 36, 121)       128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 36, 121)       0         \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 32, 36, 121)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 18, 60)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 18, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 16, 58)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 16, 58)        128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 16, 58)        0         \n",
      "_________________________________________________________________\n",
      "elu_5 (ELU)                  (None, 32, 16, 58)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 8, 29)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32, 8, 29)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 6, 27)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 6, 27)         128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 6, 27)         0         \n",
      "_________________________________________________________________\n",
      "elu_6 (ELU)                  (None, 32, 6, 27)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 32, 3, 13)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 3, 13)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1248)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               159872    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 209,026\n",
      "Trainable params: 208,834\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0905 17:17:11.900672 4481955264 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# class_weights = {0: .99, 1: .01}\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_train),\n",
    "#                                                  y_train)\n",
    "\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "# print(class_weights)\n",
    "# print(type(class_weights))\n",
    "\n",
    "# compile to experement with better results, try not to get stuck at local min\n",
    "# model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer='adam')\n",
    "\n",
    "# normal compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 509s 9ms/step - loss: 0.3821 - acc: 0.8794\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 497s 9ms/step - loss: 0.2901 - acc: 0.8996\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 492s 9ms/step - loss: 0.2666 - acc: 0.8999\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 488s 9ms/step - loss: 0.2473 - acc: 0.8999\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 488s 9ms/step - loss: 0.2366 - acc: 0.9000\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 490s 9ms/step - loss: 0.2273 - acc: 0.9000\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.2185 - acc: 0.9000\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.2137 - acc: 0.9000\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.2070 - acc: 0.9000\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.2012 - acc: 0.9000\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.1994 - acc: 0.9000\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 490s 9ms/step - loss: 0.1977 - acc: 0.9000\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.1927 - acc: 0.9000\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.1908 - acc: 0.9000\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 486s 9ms/step - loss: 0.1870 - acc: 0.9000\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 488s 9ms/step - loss: 0.1876 - acc: 0.9000\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 490s 9ms/step - loss: 0.1831 - acc: 0.9000\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 487s 9ms/step - loss: 0.1812 - acc: 0.9000\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 488s 9ms/step - loss: 0.1816 - acc: 0.9000\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 487s 9ms/step - loss: 0.1789 - acc: 0.9000\n",
      "Epoch 21/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.1772 - acc: 0.9000\n",
      "Epoch 22/40\n",
      "54000/54000 [==============================] - 488s 9ms/step - loss: 0.1758 - acc: 0.9000\n",
      "Epoch 23/40\n",
      "54000/54000 [==============================] - 487s 9ms/step - loss: 0.1721 - acc: 0.9000\n",
      "Epoch 24/40\n",
      "54000/54000 [==============================] - 490s 9ms/step - loss: 0.1732 - acc: 0.9000\n",
      "Epoch 25/40\n",
      "54000/54000 [==============================] - 25379s 470ms/step - loss: 0.1736 - acc: 0.9000\n",
      "Epoch 26/40\n",
      "54000/54000 [==============================] - 5510s 102ms/step - loss: 0.1707 - acc: 0.9064\n",
      "Epoch 27/40\n",
      "54000/54000 [==============================] - 496s 9ms/step - loss: 0.1685 - acc: 0.9126\n",
      "Epoch 28/40\n",
      "54000/54000 [==============================] - 488s 9ms/step - loss: 0.1683 - acc: 0.9161\n",
      "Epoch 29/40\n",
      "54000/54000 [==============================] - 489s 9ms/step - loss: 0.1648 - acc: 0.9138\n",
      "Epoch 30/40\n",
      "54000/54000 [==============================] - 490s 9ms/step - loss: 0.1651 - acc: 0.9159\n",
      "Epoch 31/40\n",
      "54000/54000 [==============================] - 492s 9ms/step - loss: 0.1648 - acc: 0.9167\n",
      "Epoch 32/40\n",
      "54000/54000 [==============================] - 491s 9ms/step - loss: 0.1635 - acc: 0.9171\n",
      "Epoch 33/40\n",
      "54000/54000 [==============================] - 12591s 233ms/step - loss: 0.1625 - acc: 0.9178\n",
      "Epoch 34/40\n",
      "54000/54000 [==============================] - 543s 10ms/step - loss: 0.1617 - acc: 0.9172\n",
      "Epoch 35/40\n",
      "54000/54000 [==============================] - 493s 9ms/step - loss: 0.1587 - acc: 0.9181\n",
      "Epoch 36/40\n",
      " 1800/54000 [>.............................] - ETA: 7:45 - loss: 0.1799 - acc: 0.9200"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "# we will want to add in seperated data to validate model\n",
    "# we will also want to normalize data, see docs\n",
    "# we may want to do multi channel learning\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "               epochs=40,\n",
    "               shuffle=True,\n",
    "               batch_size=300,\n",
    "#                class_weight=class_weights,\n",
    "               verbose=1)\n",
    "\n",
    "# model.fit(X_train, Y_train, \n",
    "#           batch_size=300, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"testing accuracy \" + str(score))\n",
    "\n",
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"training accuracy \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "s = 0\n",
    "b = 0\n",
    "for i in Y_train:\n",
    "    if (i[0] == 0.0):\n",
    "        b = b + 1\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        s = s + 1\n",
    "        y_train.append(1)\n",
    " \n",
    "y_train = np.array(y_train)\n",
    "print(\"training set: \")\n",
    "print(\"0 values \" + str(b))\n",
    "print(\"1 values \" + str(s))\n",
    "\n",
    "y_test = []\n",
    "s = 0\n",
    "b = 0\n",
    "\n",
    "for i in Y_test:\n",
    "    if (i[0] == 0.0):\n",
    "        b = b + 1\n",
    "        y_test.append(0)\n",
    "    else:\n",
    "        s = s + 1\n",
    "        y_test.append(1)\n",
    " \n",
    "y_test = np.array(y_test)\n",
    "print(\"testing set: \")\n",
    "print(\"0 values \" + str(b))\n",
    "print(\"1 values \" + str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 is bonafied, 0 is spoofed audio\n",
    "train_predictions = model.predict(X_train)\n",
    "confusion = confusion_matrix(y_train, np.argmax(train_predictions,axis=1))\n",
    "print(\"training matrix: \")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 is bonafied, 0 is spoofed audio\n",
    "test_predictions = model.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, np.argmax(test_predictions,axis=1))\n",
    "print(\"testing matrix: \")\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
