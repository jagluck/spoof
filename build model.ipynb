{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "# first, we need to import our essentia module.\n",
    "import essentia\n",
    "\n",
    "# as there are 2 operating modes in essentia which have the same algorithms,\n",
    "# these latter are dispatched into 2 submodules:\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "\n",
    "# # pylab contains the plot() function, as well as figure, etc... (same names as Matlab)\n",
    "# from pylab import plot, show, figure, imshow\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "# import machine learning packages\n",
    "import theano\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"jake_data/train_all.pkl\")\n",
    "test = pd.read_pickle(\"jake_data/test_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out some data to make it better distributed\n",
    "train = train[0:21600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataframe\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n",
      "16200\n",
      "5400\n",
      "24300\n"
     ]
    }
   ],
   "source": [
    "# need to figure out solution for different audio lenghts, jagged arrays?\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "X_test = np.zeros(shape=(len(test),1,13,100))\n",
    "c = 0\n",
    "for i in test[\"mfccs_files\"]:\n",
    "    l = i.shape[1]\n",
    "    b = int(math.floor((l-100)/2))\n",
    "    tp = i[0:13,b:(b + 100)]\n",
    "    X_test[c,0,:,:] = tp\n",
    "    c = c + 1\n",
    "    \n",
    "X_train = np.zeros(shape=(len(train),1,13,100))\n",
    "c = 0\n",
    "for i in train[\"mfccs_files\"]:\n",
    "    l = i.shape[1]\n",
    "    b = int(math.floor((l-100)/2))\n",
    "    tp = i[0:13,b:(b + 100)]\n",
    "    X_train[c,0,:,:] = tp\n",
    "    c = c + 1\n",
    "\n",
    "Y_train = np.zeros(shape=(len(train),2)) \n",
    "\n",
    "c = 0\n",
    "b = 0\n",
    "s = 0\n",
    "for i in train[\"output\"]:\n",
    "    if (i == \"bonafide\"):\n",
    "        b = b + 1\n",
    "        Y_train[c,:] = [np.float64(0.0),np.float64(1.0)]\n",
    "    else:\n",
    "        s = s + 1\n",
    "        Y_train[c,:] = [np.float64(1.0),np.float64(0.0)]\n",
    "    c = c + 1\n",
    "print(b)\n",
    "print(s)\n",
    "\n",
    "Y_test = np.zeros(shape=(len(test),2)) \n",
    "\n",
    "c = 0\n",
    "b = 0\n",
    "s = 0\n",
    "for i in test[\"output\"]:\n",
    "    if (i == \"bonafide\"):\n",
    "        b = b + 1\n",
    "        Y_test[c,:] = [np.float64(0.0),np.float64(1.0)]\n",
    "    else:\n",
    "        s = s + 1\n",
    "        Y_test[c,:] = [np.float64(1.0),np.float64(0.0)]\n",
    "    c = c + 1\n",
    "       \n",
    "print(b)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, 13,100)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 13,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 14:43:14.252031 4727473600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 14:43:14.286952 4727473600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 14:43:14.298325 4727473600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0826 14:43:14.314349 4727473600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0826 14:43:14.315926 4727473600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  after removing the cwd from sys.path.\n",
      "W0826 14:43:14.476664 4727473600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0826 14:43:14.483483 4727473600 deprecation.py:506] From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,13,100),data_format='channels_first'))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ELU(alpha=1.0)) \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ELU(alpha=1.0)) \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 14:43:14.897367 4727473600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# class_weights = {0: .99, 1: .01}\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_train),\n",
    "#                                                  y_train)\n",
    "\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "# print(class_weights)\n",
    "# print(type(class_weights))\n",
    "\n",
    "# compile to experement with better results, try not to get stuck at local min\n",
    "# model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer='adam')\n",
    "\n",
    "# normal compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 14:43:24.131069 4727473600 deprecation.py:323] From /usr/local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.6239 - acc: 0.7156\n",
      "Epoch 2/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.5140 - acc: 0.7495\n",
      "Epoch 3/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.4858 - acc: 0.7498\n",
      "Epoch 4/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.4611 - acc: 0.7500\n",
      "Epoch 5/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.4372 - acc: 0.7500\n",
      "Epoch 6/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.4167 - acc: 0.7500\n",
      "Epoch 7/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3975 - acc: 0.7500\n",
      "Epoch 8/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3878 - acc: 0.7708\n",
      "Epoch 9/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.3772 - acc: 0.8028\n",
      "Epoch 10/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3692 - acc: 0.8108\n",
      "Epoch 11/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3616 - acc: 0.8162\n",
      "Epoch 12/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3552 - acc: 0.8160\n",
      "Epoch 13/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.3485 - acc: 0.8221\n",
      "Epoch 14/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3439 - acc: 0.8277\n",
      "Epoch 15/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.3352 - acc: 0.8337\n",
      "Epoch 16/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.3318 - acc: 0.8331\n",
      "Epoch 17/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3360 - acc: 0.8333\n",
      "Epoch 18/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.3255 - acc: 0.8410\n",
      "Epoch 19/20\n",
      "21600/21600 [==============================] - 34s 2ms/step - loss: 0.3256 - acc: 0.8410\n",
      "Epoch 20/20\n",
      "21600/21600 [==============================] - 33s 2ms/step - loss: 0.3273 - acc: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c2e7a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "               epochs=20,\n",
    "               shuffle=True,\n",
    "               batch_size=300,\n",
    "#                class_weight=class_weights,\n",
    "               verbose=1)\n",
    "\n",
    "# model.fit(X_train, Y_train, \n",
    "#           batch_size=300, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"testing accuracy \" + str(score))\n",
    "\n",
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"training accuracy \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "s = 0\n",
    "b = 0\n",
    "for i in Y_train:\n",
    "    if (i[0] == 0.0):\n",
    "        b = b + 1\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        s = s + 1\n",
    "        y_train.append(1)\n",
    " \n",
    "y_train = np.array(y_train)\n",
    "print(\"training set: \")\n",
    "print(\"0 values \" + str(b))\n",
    "print(\"1 values \" + str(s))\n",
    "\n",
    "y_test = []\n",
    "s = 0\n",
    "b = 0\n",
    "\n",
    "for i in Y_test:\n",
    "    if (i[0] == 0.0):\n",
    "        b = b + 1\n",
    "        y_test.append(0)\n",
    "    else:\n",
    "        s = s + 1\n",
    "        y_test.append(1)\n",
    " \n",
    "y_test = np.array(y_test)\n",
    "print(\"testing set: \")\n",
    "print(\"0 values \" + str(b))\n",
    "print(\"1 values \" + str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 is bonafied, 0 is spoofed audio\n",
    "train_predictions = model.predict(X_train)\n",
    "confusion = confusion_matrix(y_train, np.argmax(train_predictions,axis=1))\n",
    "print(\"training matrix: \")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 is bonafied, 0 is spoofed audio\n",
    "test_predictions = model.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, np.argmax(test_predictions,axis=1))\n",
    "print(\"testing matrix: \")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
